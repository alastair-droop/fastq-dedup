#!/usr/bin/env python
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from __future__ import print_function

version = '1.2 (2017-11-14)'

import argparse
from sys import stdout
from os import walk
from os.path import splitext, getsize, join
import gzip
import hashlib
import json
import logging

parser = argparse.ArgumentParser(description='Generate identification data for FASTQ files')
parser.add_argument('-v', '--version', action='version', version='%(prog)s {0}'.format(version))
parser.add_argument('-V', '--verbose', dest='verbosity_level', default='error', choices=['error', 'warning', 'info', 'debug'], help='Set logging level')
parser.add_argument('-r', '--recursive', dest='recursive', action='store_true', default=False, help='recursively search folders')
parser.add_argument('-l', '--follow-links', dest='links', action='store_true', default=False, help='follow links (if running recursively)')
parser.add_argument('-c', '--checksum', dest='checksum', action='store_true', default=False, help='generate file checksums & decompressed size')
parser.add_argument('-e', '--extension', dest='extensions', action='append', help='file extensions to search')
parser.add_argument('-b', '--md5-block-size', dest='block_size', type=int, default=4096, help='file block size for calculating checksums')
parser.add_argument('-o', '--output-file', dest='output_file', type=argparse.FileType('wt'), default=stdout, help='output file')
parser.add_argument(dest='locations', metavar='<directory>', nargs='*', default=['.'], help='folder(s) to search')
args = parser.parse_args()

# Add the defualt file types if none have been specified:
if args.extensions is None: args.extensions = ['.fastq', '.fastq.gz']

# Set up logging based on the verbosity level set by the command line arguments:
log = logging.getLogger()
log_handler = logging.StreamHandler()
log.default_msec_format = ''
log_handler.setFormatter(logging.Formatter('[%(asctime)s.%(msecs)03d] %(levelname)s: %(message)s', '%Y-%m-%d %H:%M:%S'))
log.setLevel(args.verbosity_level.upper())
log.addHandler(log_handler)

def getHandle(filename):
    log.debug('attempting to open file "{}"'.format(filename))
    #First, try to open as a fastq.gz file:
    try:
        handle = gzip.open(filename, 'rb')
        header = handle.readline().decode('ASCII').strip()
        if header.startswith('@') is False: raise
        handle.seek(0)
        log.debug('opened file "{}" as fastq.gz'.format(filename))
        return (handle, 'fastq.gz')
    except (KeyboardInterrupt, SystemExit): raise
    except:
        log.debug('failed to open file "{}" as fastq.gz'.format(filename))
        pass
    #Try again as normal fastq file:
    try:
        handle = open(filename, 'rb')
        header = handle.readline().decode('ASCII').strip()
        if header.startswith('@') is False:
            log.debug('file "{}" does not have valid first line'.format(filename))
            raise
        handle.seek(0)
        log.debug('opened file "{}" as uncompressed fastq'.format(filename))
        return (handle, 'fastq')
    except (KeyboardInterrupt, SystemExit): raise
    except:
        log.debug('failed to open file "{}" as fastq'.format(filename))
        return (None, None)

# Define the warning functions:
def warn_fun(err): log.warning('failed to process directory: "{}"'.format(err))

# A function to get a file's size:
def getDiskSize(filename):
    log.debug('attempting to determine file disk size for file "{}"'.format(filename))
    try: return getsize(filename)
    except (KeyboardInterrupt, SystemExit): raise
    except:
        log.warning('failed to determine file disk size for file "{}"'.format(filename))
        return None

# A function to generate a fastq file (decompressed) MD5 checksum:
def getMD5(handle):
    if args.checksum is not True: return (None, None)
    if handle is None: return (None, None)
    log.debug('attempting to determine uncompressed MD5 for file "{}"'.format(handle.name))
    try:
        md5 = hashlib.md5()
        size = 0
        handle.seek(0)
        for chunk in iter(lambda: handle.read(args.block_size), b''):
            md5.update(chunk)
            size += len(chunk)
        return (size, md5.hexdigest())
    except (KeyboardInterrupt, SystemExit): raise
    except:
        log.warning('failed to determine uncompressed MD5 for file "{}"'.format(handle.name))
        return (None, None)

# A function to return the first (header) line of a FASTQ or FASTQ.GZ file:
def getHeader(handle):
    if handle is None: return None
    log.debug('attempting to determine initial read header for file "{}"'.format(handle.name))
    try:
        handle.seek(0)
        return handle.readline().decode('ASCII').strip()
    except (KeyboardInterrupt, SystemExit): raise
    except:
        log.warning('failed to determine initial read header for file "{}"'.format(handle.name))
        return None

# Output the run settings:
log.debug('testing files with extensions: "{}"'.format('", "'.join(args.extensions)))
if args.checksum is True: log.debug('generating MD5 checksums with blocksize of {} bytes'.format(args.block_size))
else: log.debug('skipping MD5 checksums')
if args.recursive is True:
    log.debug('recursively checking subfolders')
    if args.links is True: log.debug('following links')
    else: log.debug('not following links')
else:
    log.debug('not recursively checking subfolders')
    log.debug('not following links (not recursive)')

# Create an output dictionary:
output = []

# Iterate through the input folders, building up the output data:
for input_location in args.locations:
    for root, subdirs, files in walk(input_location, topdown=True, followlinks=args.links, onerror=warn_fun):
        try:
            log.info('processing directory "{}"'.format(root))
            # Prevent recursion, if necessary:
            if args.recursive is False:
                while len(subdirs) > 0: subdirs.pop()
            # Go through the remaining files, checking them:
            for f in files:
                log.debug('processing file "{}"'.format(f))
                for ext in args.extensions:
                    if f.endswith(ext):
                        # The file has the relevant extension, so should be processed:
                        f_path = join(root, f)
                        f_handle = getHandle(f_path)
                        f_data = getMD5(f_handle[0])
                        file_data = {'dir':root, 'name':f, 'format':f_handle[1]}
                        file_data['disk'] = getDiskSize(f_path)
                        file_data['size'] = f_data[0]
                        file_data['checksum'] = f_data[1]
                        file_data['header'] = getHeader(f_handle[0])
                        output.append(file_data)
        except (KeyboardInterrupt, SystemExit): raise

# Print out the data:
log.debug('writing output data to file "{}"'.format(args.output_file.name))
print(json.dumps(output, indent=2), file=args.output_file)
